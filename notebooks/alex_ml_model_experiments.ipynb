{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T17:48:16.596169Z",
     "start_time": "2024-12-09T17:48:07.438595Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Model",
   "id": "1105bda5af1b4307"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:12:52.907357Z",
     "start_time": "2024-12-09T18:12:52.897357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PointCloudAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=3, bottleneck_size=128, num_points=1024):\n",
    "        super(PointCloudAutoEncoder, self).__init__()\n",
    "        self.num_points = num_points\n",
    "\n",
    "        # Encoder: Maps input point cloud to a latent representation\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, bottleneck_size, kernel_size=1),\n",
    "            nn.AdaptiveMaxPool1d(1)\n",
    "        )\n",
    "\n",
    "        # Decoder: Maps latent representation back to point cloud\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_points * input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, num_points, input_dim]\n",
    "        \n",
    "        # Encoder\n",
    "        x = x.permute(0, 2, 1)  # Change to [batch_size, input_dim, num_points]\n",
    "        latent = self.encoder(x)  # [batch_size, bottleneck_size, 1]\n",
    "        latent = latent.view(latent.size(0), -1)  # [batch_size, bottleneck_size]\n",
    "\n",
    "        # Decoder\n",
    "        reconstructed = self.decoder(latent)  # [batch_size, num_points * input_dim]\n",
    "        reconstructed = reconstructed.view(-1, self.num_points, 3)  # [batch_size, num_points, input_dim]\n",
    "        \n",
    "        return reconstructed"
   ],
   "id": "59e4f371fab4d0ef",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:13:00.214258Z",
     "start_time": "2024-12-09T18:13:00.205997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# LOSS METHODS\n",
    "#\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "def chamfer_loss(pred, target):\n",
    "    \"\"\"\n",
    "    Computes the Chamfer Distance between two point clouds.\n",
    "    Args:\n",
    "        pred: Predicted point cloud [batch_size, num_points, 3]\n",
    "        target: Ground truth point cloud [batch_size, num_points, 3]\n",
    "    Returns:\n",
    "        Chamfer distance (scalar).\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances\n",
    "    pred_expand = pred.unsqueeze(2)  # [batch_size, num_points, 1, 3]\n",
    "    target_expand = target.unsqueeze(1)  # [batch_size, 1, num_points, 3]\n",
    "    dist = torch.norm(pred_expand - target_expand, dim=-1)  # [batch_size, num_points, num_points]\n",
    "\n",
    "    # Find nearest neighbors\n",
    "    dist_to_target = torch.min(dist, dim=2)[0]  # Distance from pred to target\n",
    "    dist_to_pred = torch.min(dist, dim=1)[0]  # Distance from target to pred\n",
    "\n",
    "    # Average distances\n",
    "    loss = torch.mean(dist_to_target) + torch.mean(dist_to_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "COMBINED LOSS\n",
    "\"\"\"\n",
    "def combined_loss(pred, target):\n",
    "    return chamfer_loss(pred, target)\n",
    "    #loss_fn = MSELoss()\n",
    "    #mse_loss = loss_fn(pred, target)\n",
    "    #ch_loss = chamfer_loss(pred, target)\n",
    "    #return (mse_loss + ch_loss) * 0.5\n",
    "    "
   ],
   "id": "a588be6ed7444240",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "fede8cca442fa41c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:13:03.141541Z",
     "start_time": "2024-12-09T18:13:03.116032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def downsample_point_cloud(point_cloud, target_points=1024):\n",
    "    \"\"\"\n",
    "    Uniformly downsamples a point cloud to a fixed number of points.\n",
    "    Args:\n",
    "        point_cloud (torch.Tensor): Input point cloud of shape [num_points, 3].\n",
    "        target_points (int): Desired number of points in the output.\n",
    "    Returns:\n",
    "        torch.Tensor: Downsampled point cloud of shape [target_points, 3].\n",
    "    \"\"\"\n",
    "    num_points = point_cloud.shape[0]\n",
    "    if num_points > target_points:\n",
    "        indices = torch.randperm(num_points)[:target_points]  # Randomly select indices\n",
    "        return point_cloud[indices]\n",
    "    elif num_points < target_points:\n",
    "        # Upsample by duplicating points\n",
    "        repeat_factor = (target_points + num_points - 1) // num_points\n",
    "        extended = point_cloud.repeat(repeat_factor, 1)[:target_points]\n",
    "        return extended\n",
    "    return point_cloud\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"train\", target_points=1024, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Root directory containing subfolders with .ply files.\n",
    "            split (str): 'train' or 'val'. Determines the file names.\n",
    "            target_points (int): Number of points to standardize the point clouds to.\n",
    "            transform (callable, optional): Optional transform to apply to the point clouds.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.target_points = target_points\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        # Gather all subfolder paths and corresponding files\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            subfolder_path = os.path.join(root_dir, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                incomplete_path = os.path.join(subfolder_path, f\"{subfolder}h.ply\")\n",
    "                ground_truth_path = os.path.join(subfolder_path, f\"{subfolder}.ply\")\n",
    "                if os.path.exists(incomplete_path) and os.path.exists(ground_truth_path):\n",
    "                    self.samples.append((incomplete_path, ground_truth_path))\n",
    "                    \n",
    "        print(f\"Created dataset with {len(self.samples)} entries\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the incomplete and ground truth point clouds\n",
    "        incomplete_path, ground_truth_path = self.samples[idx]\n",
    "\n",
    "        incomplete_pcd = o3d.io.read_point_cloud(incomplete_path)\n",
    "        ground_truth_pcd = o3d.io.read_point_cloud(ground_truth_path)\n",
    "\n",
    "        incomplete_points = torch.tensor(incomplete_pcd.points, dtype=torch.float32)\n",
    "        ground_truth_points = torch.tensor(ground_truth_pcd.points, dtype=torch.float32)\n",
    "\n",
    "        # Downsample or upsample to the target number of points\n",
    "        incomplete_points = downsample_point_cloud(incomplete_points, target_points=self.target_points)\n",
    "        ground_truth_points = downsample_point_cloud(ground_truth_points, target_points=self.target_points)\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            incomplete_points = self.transform(incomplete_points)\n",
    "            ground_truth_points = self.transform(ground_truth_points)\n",
    "\n",
    "        return incomplete_points, ground_truth_points\n",
    "    \n",
    "def visualize_point_cloud(tensor_point_cloud):\n",
    "    \"\"\"\n",
    "    Visualizes a point cloud stored as a PyTorch tensor using Open3D.\n",
    "    Args:\n",
    "        tensor_point_cloud (torch.Tensor): Point cloud of shape [num_points, 3].\n",
    "    \"\"\"\n",
    "    # Ensure the tensor is detached and converted to a NumPy array\n",
    "    points = tensor_point_cloud.detach().cpu().numpy()\n",
    "\n",
    "    # Create an Open3D PointCloud object\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    \n",
    "def plot_point_cloud(numpy_point_cloud):   \n",
    "    # Create a 3D scatter plot with matplotlib\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Scatter plot of the point cloud\n",
    "    ax.scatter(numpy_point_cloud[:, 2], numpy_point_cloud[:, 1], numpy_point_cloud[:, 2], s=1)\n",
    "    \n",
    "    # Set labels\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "id": "b8b385aec956ab56",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "a04271f8dcc50c46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:13:07.245944Z",
     "start_time": "2024-12-09T18:13:07.234946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_autoencoder(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for incomplete_pc, ground_truth_pc in dataloader:\n",
    "            incomplete_pc = incomplete_pc.to(device)\n",
    "            ground_truth_pc = ground_truth_pc.to(device)\n",
    "\n",
    "            # Get the reconstructed point cloud\n",
    "            reconstructed_pc = model(incomplete_pc)\n",
    "\n",
    "            # Calculate the loss against the ground truth\n",
    "            loss = combined_loss(reconstructed_pc, ground_truth_pc)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "def train_with_ground_truth(model, optimizer, train_loader, val_loader, epochs=50, device='cuda'):\n",
    "    model.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for incomplete_pc, ground_truth_pc in train_loader:\n",
    "            incomplete_pc = incomplete_pc.to(device)\n",
    "            ground_truth_pc = ground_truth_pc.to(device)\n",
    "\n",
    "            # Reconstruct point cloud\n",
    "            reconstructed_pc = model(incomplete_pc)\n",
    "\n",
    "            # Compute loss against ground truth\n",
    "            loss = combined_loss(reconstructed_pc, ground_truth_pc)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = validate_autoencoder(model, val_loader, device)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "9308fa7f83e43c94",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:13:11.002442Z",
     "start_time": "2024-12-09T18:13:10.249651Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Dataset root directory\n",
    "root_dir = \"../assets/pcd\"\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "full_dataset = PointCloudDataset(root_dir=root_dir, split=\"train\", target_points=4096)\n",
    "\n",
    "# Define the split ratio (e.g., 80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "#demo_entry = val_dataset[1]\n",
    "#visualize_point_cloud(demo_entry)"
   ],
   "id": "d105d8eb06e6b5fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 2445 entries\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:13:35.032709Z",
     "start_time": "2024-12-09T18:13:34.926812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize model, optimizer\n",
    "input_dim = 3\n",
    "bottleneck_size = 512\n",
    "num_points = 4096\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = PointCloudAutoEncoder(input_dim=input_dim, bottleneck_size=bottleneck_size, num_points=num_points)"
   ],
   "id": "dbae4a5d88da3078",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T18:13:59.848443Z",
     "start_time": "2024-12-09T18:13:39.602302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train with grund truth\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_with_ground_truth(model, optimizer, train_loader, val_loader, epochs=epochs, device=device)"
   ],
   "id": "85d389ffe7bafd28",
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 8.67 GiB is allocated by PyTorch, and 76.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train with grund truth\u001B[39;00m\n\u001B[0;32m      2\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtrain_with_ground_truth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[33], line 40\u001B[0m, in \u001B[0;36mtrain_with_ground_truth\u001B[1;34m(model, optimizer, train_loader, val_loader, epochs, device)\u001B[0m\n\u001B[0;32m     37\u001B[0m loss \u001B[38;5;241m=\u001B[39m combined_loss(reconstructed_pc, ground_truth_pc)\n\u001B[0;32m     39\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 40\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     43\u001B[0m total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 8.67 GiB is allocated by PyTorch, and 76.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation / Test",
   "id": "bbfc33e577972c29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:27:04.810368Z",
     "start_time": "2024-12-09T16:27:03.460613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get a single example\n",
    "pd_input, pd_truth = train_dataset[9]  # First sample from the dataset\n",
    "pd_input = pd_input.unsqueeze(0)  # Add batch dimension (1, num_points, 3)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pd_input = pd_input.to(device)\n",
    "\n",
    "#state_dict = torch.load(\"../assets/model_exports/model_v1.pt\")\n",
    "#model.load_state_dict(state_dict)\n",
    "#model.eval()\n",
    "\n",
    "# Run through the model\n",
    "with torch.no_grad():\n",
    "    reconstructed_pc = model(pd_input)\n",
    "    \n",
    "# Remove batch dimension\n",
    "pd_input = pd_input.squeeze(0).cpu()\n",
    "reconstructed_pc = reconstructed_pc.squeeze(0).cpu()\n",
    "pd_truth = pd_truth.cpu()\n",
    "visualize_point_cloud(pd_input)\n",
    "visualize_point_cloud(pd_truth)\n",
    "visualize_point_cloud(reconstructed_pc)\n",
    "#plot_point_cloud(pd_truth)"
   ],
   "id": "3996d310a69501f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_31812\\147094157.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"../assets/model_exports/model_v1.pt\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Run through the model\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 13\u001B[0m     reconstructed_pc \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Remove batch dimension\u001B[39;00m\n\u001B[0;32m     16\u001B[0m pd_input \u001B[38;5;241m=\u001B[39m pd_input\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mcpu()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[17], line 34\u001B[0m, in \u001B[0;36mPointCloudAutoEncoder.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;66;03m# x: [batch_size, num_points, input_dim]\u001B[39;00m\n\u001B[0;32m     31\u001B[0m     \n\u001B[0;32m     32\u001B[0m     \u001B[38;5;66;03m# Encoder\u001B[39;00m\n\u001B[0;32m     33\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Change to [batch_size, input_dim, num_points]\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m     latent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# [batch_size, bottleneck_size, 1]\u001B[39;00m\n\u001B[0;32m     35\u001B[0m     latent \u001B[38;5;241m=\u001B[39m latent\u001B[38;5;241m.\u001B[39mview(latent\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# [batch_size, bottleneck_size]\u001B[39;00m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;66;03m# Decoder\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001B[0m, in \u001B[0;36mConv1d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 375\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ods\\lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001B[0m, in \u001B[0;36mConv1d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv1d(\n\u001B[0;32m    360\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[0;32m    361\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    368\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[0;32m    369\u001B[0m     )\n\u001B[1;32m--> 370\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    371\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[0;32m    372\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:26:55.215845Z",
     "start_time": "2024-12-06T18:26:55.149294Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model, '../assets/model_exports/model_v2.pt')",
   "id": "8af0450c3ec400b2",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Other Experiments",
   "id": "85dd70c14ed23872"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing the Losses",
   "id": "329b13a9a4196f7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:43:53.657818Z",
     "start_time": "2024-12-09T17:43:53.606199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# IOU Loss visualization\n",
    "#\n",
    "\n",
    "pd_input, pd_truth = train_dataset[9]\n",
    "pd_input = pd_input.unsqueeze(0)\n",
    "print(np.shape(pd_input))\n",
    "pd_truth = pd_truth.unsqueeze(0)\n",
    "\n",
    "#input_voxels = voxelize_point_cloud(pd_input, voxel_size=0.1)\n",
    "\n",
    "#print(f\"IOUT Loss: {iou_loss(pd_input, pd_truth)}\")\n",
    "print(f\"Chamfer Loss Loss: {chamfer_loss(pd_input, pd_truth)}\")"
   ],
   "id": "c00f7f3f7d3460dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 3])\n",
      "Chamfer Loss Loss: 0.3967241942882538\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
