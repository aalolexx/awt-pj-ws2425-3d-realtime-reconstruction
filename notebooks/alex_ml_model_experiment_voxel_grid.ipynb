{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-15T22:34:20.877126Z",
     "start_time": "2024-12-15T22:34:15.971095Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, Subset, SubsetRandomSampler"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Model",
   "id": "1105bda5af1b4307"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T22:34:21.061164Z",
     "start_time": "2024-12-15T22:34:21.048162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PointCloudAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=32):\n",
    "        super(PointCloudAutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder: Maps input point cloud to a latent representation\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, stride=2, padding=1),  # Output: (32, input_dim/2, input_dim/2, input_dim/2)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, stride=2, padding=1),  # Output: (64, input_dim/4, input_dim/4, input_dim/4)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Fully connected layers to create a bottleneck\n",
    "        grid_count = (input_dim // 4) ** 3\n",
    "        self.flatBottleneck = nn.Sequential(\n",
    "            nn.Flatten(),  # Flatten to (N, 64 * grid_count)\n",
    "            nn.Linear(32 * grid_count, 32 * grid_count),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32 * grid_count, 32 * grid_count),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(32, input_dim // 4, input_dim // 4, input_dim // 4))  # Reshape back\n",
    "        )\n",
    "        \n",
    "        #self.flatten = nn.Flatten()  # Flatten spatial dimensions\n",
    "        # self.fc1 = nn.Linear(128 * (input_dim // 8) ** 3, 128 * (input_dim // 8) ** 3)\n",
    "        #self.fc2 = nn.Linear(128, 128 * (input_dim // 8) ** 3)\n",
    "        #self.fc3 = nn.Linear( 128 * (input_dim // 8) ** 3, 128 * (input_dim // 8) ** 3)\n",
    "        #self.fc4 = nn.Linear( 128 * (input_dim // 8) ** 3, 128 * (input_dim // 8) ** 3)\n",
    "        #self.unflatten = nn.Unflatten(128 * (input_dim // 8) ** 3, (128, input_dim // 8, input_dim // 8, input_dim // 8))\n",
    "        \n",
    "        # Decoder: Maps latent representation back to point cloud\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),  # Output values in [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)  # Encode spatial features\n",
    "        x = self.flatBottleneck(x)\n",
    "        x = self.decoder(x)  # Decode back to voxel grid\n",
    "        return x"
   ],
   "id": "59e4f371fab4d0ef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T22:34:21.660824Z",
     "start_time": "2024-12-15T22:34:21.653823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# LOSS METHODS\n",
    "#\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import BCELoss\n",
    "\n",
    "\"\"\"\n",
    "COMBINED LOSS\n",
    "\"\"\"\n",
    "def combined_loss(pred, target):\n",
    "    loss_fn = BCELoss()\n",
    "    return loss_fn(pred, target)\n",
    "    "
   ],
   "id": "a588be6ed7444240",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "fede8cca442fa41c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:34:21.350061Z",
     "start_time": "2024-12-16T13:34:21.331056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VoxelGridDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"train\",transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Root directory containing subfolders with .ply files.\n",
    "            split (str): 'train' or 'val'. Determines the file names.\n",
    "            target_points (int): Number of points to standardize the point clouds to.\n",
    "            transform (callable, optional): Optional transform to apply to the point clouds.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        self.voxel_size = None\n",
    "        self.grid_min_bound = None\n",
    "        self.grid_min_bound = None\n",
    "\n",
    "        # Gather all subfolder paths and corresponding files\n",
    "        \"\"\"\n",
    "        for subfolder in os.listdir(root_dir):\n",
    "            subfolder_path = os.path.join(root_dir, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                incomplete_path = os.path.join(subfolder_path, f\"{subfolder}h.ply\")\n",
    "                ground_truth_path = os.path.join(subfolder_path, f\"{subfolder}.ply\")\n",
    "                if os.path.exists(incomplete_path) and os.path.exists(ground_truth_path):\n",
    "                    self.samples.append((incomplete_path, ground_truth_path))\n",
    "        \"\"\"\n",
    "        \n",
    "        lst = os.listdir(root_dir) # your directory path\n",
    "        number_files = len(lst)\n",
    "\n",
    "        for i in range(math.floor(number_files / 2)):\n",
    "            cut_file_path = os.path.join(root_dir, f\"{i}_cut.ply\")\n",
    "            full_file_path = os.path.join(root_dir, f\"{i}_full.ply\")\n",
    "            if os.path.exists(cut_file_path) and os.path.exists(full_file_path):\n",
    "                self.samples.append((cut_file_path, full_file_path))\n",
    "                    \n",
    "        print(f\"Created dataset with {len(self.samples)} entries\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the incomplete and ground truth point clouds\n",
    "        incomplete_path, ground_truth_path = self.samples[idx]\n",
    "\n",
    "        incomplete_pcd = o3d.io.read_point_cloud(incomplete_path)\n",
    "        ground_truth_pcd = o3d.io.read_point_cloud(ground_truth_path)\n",
    "\n",
    "        incomplete_points = self.get_3d_tensor_from_pcd(incomplete_pcd)\n",
    "        ground_truth_points = self.get_3d_tensor_from_pcd(ground_truth_pcd)\n",
    "        \n",
    "        # add one color channel for tensor format\n",
    "        incomplete_points = incomplete_points.unsqueeze(0)\n",
    "        ground_truth_points = ground_truth_points.unsqueeze(0) \n",
    "\n",
    "        return incomplete_points, ground_truth_points\n",
    "    \n",
    "    \n",
    "    def get_3d_tensor_from_pcd(self, pcd):\n",
    "        # Extract the points\n",
    "        points = np.asarray(pcd.points)\n",
    "        # Get the bounding box of the point cloud to determine the extent of the grid\n",
    "        min_bound = np.min(points, axis=0)\n",
    "        max_bound = np.max(points, axis=0)\n",
    "        # Define the resolution of the 3D grid (e.g., 50x50x50 grid)\n",
    "        grid_size = 32 # TODO IN PARAMS\n",
    "        voxel_size = (max_bound - min_bound) / grid_size\n",
    "        \n",
    "        self.voxel_size = voxel_size\n",
    "        self.grid_min_bound = min_bound\n",
    "        self.grid_min_bound = max_bound\n",
    "        \n",
    "        # Normalize the points to the grid space\n",
    "        normalized_points = (points - min_bound) / voxel_size\n",
    "        # Round the points to the nearest grid cell\n",
    "        grid_points = np.floor(normalized_points).astype(int)\n",
    "        # Clamp the values to ensure they stay within grid bounds\n",
    "        grid_points = np.clip(grid_points, 0, grid_size - 1)\n",
    "        # Create the 3D tensor (grid), initially filled with zeros\n",
    "        grid_tensor = torch.zeros((grid_size, grid_size, grid_size), dtype=torch.int32)\n",
    "        # Mark the grid cells corresponding to the points as occupied (1)\n",
    "        for point in grid_points:\n",
    "            grid_tensor[tuple(point)] = 1\n",
    "        return grid_tensor.float()\n",
    "    \n",
    "def visualize_3d_torch(tensor_3d, min_bound, voxel_size=1, threshold=0.5, window_name=\"Open3D Vis\"):\n",
    "     # Assume a default min_bound if it's not provided\n",
    "    if min_bound is None:\n",
    "        min_bound = np.array([1, 1, 1])  # Default assumption\n",
    "\n",
    "    # Find indices of non-zero elements in the tensor\n",
    "    occupied_indices = np.argwhere(tensor_3d.numpy() > 0)\n",
    "    # Convert grid indices back to world coordinates\n",
    "    points = occupied_indices * voxel_size + min_bound\n",
    "    # Create a point cloud using Open3D\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.visualization.draw_geometries([pcd], window_name=window_name)"
   ],
   "id": "b8b385aec956ab56",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "a04271f8dcc50c46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T22:34:25.234575Z",
     "start_time": "2024-12-15T22:34:25.220573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_autoencoder(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for incomplete_pc, ground_truth_pc in dataloader:\n",
    "            incomplete_pc = incomplete_pc.to(device)\n",
    "            ground_truth_pc = ground_truth_pc.to(device)\n",
    "\n",
    "            # Get the reconstructed point cloud\n",
    "            reconstructed_pc = model(incomplete_pc)\n",
    "\n",
    "            # Calculate the loss against the ground truth\n",
    "            loss = combined_loss(reconstructed_pc, ground_truth_pc)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "def train_with_ground_truth(model, optimizer, train_loader, val_loader, epochs=50, device='cuda'):\n",
    "    model.to(device)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience = 7\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    print(\"starting epochs\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        for incomplete_pc, ground_truth_pc in train_loader:\n",
    "            incomplete_pc = incomplete_pc.to(device)\n",
    "            ground_truth_pc = ground_truth_pc.to(device)\n",
    "                            \n",
    "            # Reconstruct point cloud\n",
    "            reconstructed_pc = model(incomplete_pc)\n",
    "\n",
    "            # Compute loss against ground truth\n",
    "            loss = combined_loss(reconstructed_pc, ground_truth_pc)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = validate_autoencoder(model, val_loader, device)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_train_loss < best_loss:\n",
    "            best_loss = avg_train_loss\n",
    "            patience = 7  # Reset patience counter\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                print(\"EARLY STOPPING DUE TO MISSING PROGRESS\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "9308fa7f83e43c94",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T22:34:38.560698Z",
     "start_time": "2024-12-15T22:34:33.732682Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Dataset root directory\n",
    "root_dir = \"../assets/voxel10000\"\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "full_dataset = VoxelGridDataset(root_dir=root_dir, split=\"train\")\n",
    "\n",
    "#limit to 10k\n",
    "indices = np.random.choice(len(full_dataset), size=8000, replace=False)\n",
    "subset_d = Subset(full_dataset, indices)\n",
    "\n",
    "# Define the split ratio (e.g., 80% train, 20% validation)\n",
    "train_size = int(0.8 * len(subset_d))\n",
    "val_size = len(subset_d) - train_size\n",
    "print(f\"train size: {train_size}, val size: {val_size}\")\n",
    "train_dataset, val_dataset = random_split(subset_d, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "demo_entry = val_dataset[1]\n",
    "print(np.shape(demo_entry))\n",
    "\n",
    "#visualize_3d_torch(demo_entry[1][0])\n",
    "#visualize_3d_torch(demo_entry[0][0])\n",
    "#full_dataset.visualize_3d_torch(demo_entry[0])\n",
    "#print(demo_entry)\n",
    "#visualize_point_cloud(demo_entry)"
   ],
   "id": "d105d8eb06e6b5fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 29340 entries\n",
      "train size: 6400, val size: 1600\n",
      "(2, 1, 32, 32, 32)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T22:34:44.431760Z",
     "start_time": "2024-12-15T22:34:41.542324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize model, optimizer\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model = PointCloudAutoEncoder()"
   ],
   "id": "dbae4a5d88da3078",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:13:52.307985Z",
     "start_time": "2024-12-15T22:34:46.704230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train with grund truth\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_with_ground_truth(model, optimizer, train_loader, val_loader, epochs=epochs, device=device)"
   ],
   "id": "85d389ffe7bafd28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epochs\n",
      "Epoch 1/20, Train Loss: 0.2329, Val Loss: 0.2072\n",
      "Epoch 2/20, Train Loss: 0.1961, Val Loss: 0.1960\n",
      "Epoch 3/20, Train Loss: 0.1772, Val Loss: 0.1901\n",
      "Epoch 4/20, Train Loss: 0.1608, Val Loss: 0.1915\n",
      "Epoch 5/20, Train Loss: 0.1481, Val Loss: 0.1966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train with grund truth\u001B[39;00m\n\u001B[0;32m      2\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtrain_with_ground_truth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 49\u001B[0m, in \u001B[0;36mtrain_with_ground_truth\u001B[1;34m(model, optimizer, train_loader, val_loader, epochs, device)\u001B[0m\n\u001B[0;32m     46\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     47\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 49\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m avg_train_loss \u001B[38;5;241m=\u001B[39m total_train_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[0;32m     52\u001B[0m avg_val_loss \u001B[38;5;241m=\u001B[39m validate_autoencoder(model, val_loader, device)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation / Test",
   "id": "bbfc33e577972c29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:54:58.649382Z",
     "start_time": "2024-12-16T13:54:51.195337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get a single example\n",
    "pd_input, pd_truth = train_dataset[3]  # First sample from the dataset\n",
    "pd_input = pd_input.unsqueeze(0)  # Add batch dimension (1, num_points, 3)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pd_input = pd_input.to(device)\n",
    "\n",
    "#state_dict = torch.load(\"../assets/model_exports/model_v1.pt\")\n",
    "#model.load_state_dict(state_dict)\n",
    "#model.eval()\n",
    "\n",
    "# Run through the model\n",
    "with torch.no_grad():\n",
    "    reconstructed_pc = model(pd_input)\n",
    "    \n",
    "# Remove batch dimension\n",
    "pd_input = pd_input.squeeze(0).cpu()\n",
    "reconstructed_pc = reconstructed_pc.squeeze(0).cpu()\n",
    "pd_truth = pd_truth.cpu()\n",
    "#plot_point_cloud(pd_truth)\n",
    "\n",
    "#print(torch.max(reconstructed_pc))\n",
    "reconstructed_pc = torch.where(reconstructed_pc > 0.5, 1, 0)\n",
    "print(\"reconstructed\")\n",
    "print(f\"shape: {np.shape(reconstructed_pc)}\")\n",
    "print(f\"max: {torch.max(reconstructed_pc)}\")\n",
    "print(f\"sum == 1: {torch.sum(reconstructed_pc == 1)}\")\n",
    "print(f\"sum == 0: {torch.sum(reconstructed_pc == 0)}\")\n",
    "print(f\"shape: {torch.max(pd_input)}\")\n",
    "print(f\"max: {np.shape(pd_input)}\")\n",
    "print(f\"sum == 1: {torch.sum(pd_input == 1)}\")\n",
    "print(f\"sum == 0: {torch.sum(pd_input == 0)}\")\n",
    "\n",
    "voxel_size = 0.01  # Assuming the original grid covered a 10x10x10 space\n",
    "min_bound = np.array([3, 1, 2])  # Assume min_bound was at origin\n",
    "    \n",
    "visualize_3d_torch(pd_input[0], voxel_size, min_bound, window_name=\"Input\")\n",
    "visualize_3d_torch(pd_truth[0], voxel_size, min_bound, window_name=\"Ground Truth\")\n",
    "visualize_3d_torch(reconstructed_pc[0], voxel_size, min_bound, window_name=\"Predicted\")"
   ],
   "id": "3996d310a69501f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed\n",
      "shape: torch.Size([1, 32, 32, 32])\n",
      "max: 1\n",
      "sum == 1: 2160\n",
      "sum == 0: 30608\n",
      "shape: 1.0\n",
      "max: torch.Size([1, 32, 32, 32])\n",
      "sum == 1: 1079\n",
      "sum == 0: 31689\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:38:46.669916Z",
     "start_time": "2024-12-16T13:38:33.221045Z"
    }
   },
   "cell_type": "code",
   "source": "#torch.save(model, '../assets/model_exports/model_v3.pt')",
   "id": "8af0450c3ec400b2",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Other Experiments",
   "id": "85dd70c14ed23872"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing the Losses",
   "id": "329b13a9a4196f7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:43:53.657818Z",
     "start_time": "2024-12-09T17:43:53.606199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# IOU Loss visualization\n",
    "#\n",
    "\n",
    "pd_input, pd_truth = train_dataset[9]\n",
    "pd_input = pd_input.unsqueeze(0)\n",
    "print(np.shape(pd_input))\n",
    "pd_truth = pd_truth.unsqueeze(0)\n",
    "\n",
    "#input_voxels = voxelize_point_cloud(pd_input, voxel_size=0.1)\n",
    "\n",
    "#print(f\"IOUT Loss: {iou_loss(pd_input, pd_truth)}\")\n",
    "print(f\"Chamfer Loss Loss: {chamfer_loss(pd_input, pd_truth)}\")"
   ],
   "id": "c00f7f3f7d3460dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 3])\n",
      "Chamfer Loss Loss: 0.3967241942882538\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
