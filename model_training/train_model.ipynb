{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Notebook\n",
    "\n",
    "## Description\n",
    "\n",
    "This notebook serves as an small example to how we trained and tested our networks.\n",
    "In progress of the project multiple models were tested, this only serves as one example.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "These are some helper functions and are mostly the same functions like in the data_creation.ipynb notebook.\n",
    "\n",
    "To keep this notebook short we left out the documentation, since the functions hopefully self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================\n",
    "#  Load Point Cloud\n",
    "# ==================================================================================================\n",
    "def load_pcd(file_path):\n",
    "    return o3d.io.read_point_cloud(file_path)\n",
    "\n",
    "# ==================================================================================================\n",
    "#  Generate Rotated View\n",
    "# ==================================================================================================\n",
    "def generate_rotated_view(pcd, rotation_angle_deg):\n",
    "    rotation_angle_rad = np.deg2rad(rotation_angle_deg)\n",
    "    R = pcd.get_rotation_matrix_from_xyz((0, rotation_angle_rad, 0))\n",
    "    rot_copy = copy.deepcopy(pcd).rotate(R, center=[0,0,0])\n",
    "    bound_difference = np.asarray(rot_copy.get_max_bound()) - np.asarray(rot_copy.get_min_bound())\n",
    "    diameter = np.linalg.norm(bound_difference)\n",
    "    c = rot_copy.get_center()\n",
    "    camera = o3d.core.Tensor([c[0], c[1], diameter], o3d.core.float64)\n",
    "    radius = diameter * 100\n",
    "    tensor_pcd = o3d.t.geometry.PointCloud.from_legacy(rot_copy)\n",
    "    _, pt_map = tensor_pcd.hidden_point_removal(camera, radius)\n",
    "    tensor_pcd = tensor_pcd.select_by_index(pt_map)\n",
    "    pcd_cut = tensor_pcd.to_legacy()\n",
    "    return rot_copy, pcd_cut\n",
    "\n",
    "# ==================================================================================================\n",
    "#  Normalize\n",
    "# ==================================================================================================\n",
    "def normalize(pcd):\n",
    "    bounding_box = pcd.get_axis_aligned_bounding_box()\n",
    "    center = bounding_box.get_center()\n",
    "    pcd.translate(-center)\n",
    "\n",
    "    min_bound = pcd.get_min_bound()\n",
    "    max_bound = pcd.get_max_bound()\n",
    "\n",
    "    extents = max_bound - min_bound\n",
    "    scale_factors = []\n",
    "    for d in extents:\n",
    "        scale_factors.append(2.0 / d)\n",
    "\n",
    "    scale_factors = np.array(scale_factors)\n",
    "\n",
    "    scale_full = scale_factors * (31.5, 63.5, 31.5)\n",
    "    points = np.asarray(pcd.points)\n",
    "    points = points * scale_full\n",
    "    points = points + (32,64,32)\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.around(points, decimals=4))\n",
    "\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================\n",
    "#  Voxel Dataset\n",
    "# ==================================================================================================\n",
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, in_dir, gt_dir, dimensions = (64, 128, 64)):\n",
    "        self.in_dir = in_dir\n",
    "        self.gt_dir = gt_dir\n",
    "        self.dimensions = dimensions\n",
    "        self.aabb = o3d.geometry.AxisAlignedBoundingBox(min_bound=(-1, -1, -1), max_bound=(1, 1, 1))\n",
    "        \n",
    "        self.in_files = sorted([f for f in os.listdir(in_dir) if f.endswith(\".ply\")])\n",
    "        self.gt_files = sorted([f for f in os.listdir(gt_dir) if f.endswith(\".ply\")])\n",
    "        assert len(self.in_files) == len(self.gt_files), \"Mismatch input and ground truth files\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.in_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Random augmentations an their probabilities\n",
    "        rot_angle = random.random() * 360.0\n",
    "        mirroring = random.random()\n",
    "        crop_distance = random.random() * 0.4\n",
    "        crop_prob = random.random()\n",
    "\n",
    "        # Prepare the input data\n",
    "        input_volume = np.zeros(self.dimensions, dtype=np.float32)\n",
    "        in_path = os.path.join(self.in_dir, self.in_files[idx])\n",
    "        pcd_in = load_pcd(in_path)\n",
    "        _, pcd_cut = generate_rotated_view(pcd_in, rot_angle)\n",
    "\n",
    "        # Apply random augmentations\n",
    "        if mirroring < 0.5: # mirror\n",
    "            mirror_transform = np.array([\n",
    "                [-1,  0,  0,  0],\n",
    "                [ 0,  1,  0,  0],\n",
    "                [ 0,  0,  1,  0],\n",
    "                [ 0,  0,  0,  1]\n",
    "            ])\n",
    "            pcd_cut.transform(mirror_transform)\n",
    "\n",
    "        if crop_prob < 0.3: # crop\n",
    "            cd = -0.2 - crop_distance\n",
    "            y_transform = np.array([\n",
    "                [ 1,  0,  0,   0],\n",
    "                [ 0,  1,  0,  cd],\n",
    "                [ 0,  0,  1,   0],\n",
    "                [ 0,  0,  0,   1]\n",
    "            ])\n",
    "            pcd_cut.transform(y_transform)\n",
    "            pcd_cut = pcd_cut.crop(self.aabb)\n",
    "\n",
    "        # Normalize point cloud into bounding box and construct input tensor\n",
    "        norm_pcd_cut = normalize(pcd_cut)\n",
    "        input_points = np.asarray(norm_pcd_cut.points, dtype=np.uint8)\n",
    "        for (x, y, z) in input_points:\n",
    "            input_volume[x, y, z] = 1\n",
    "\n",
    "        input_tensor = torch.tensor(input_volume, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "\n",
    "        # Prepare the ground truth data\n",
    "        target_volume = np.zeros(self.dimensions, dtype=np.float32)\n",
    "        gt_path = os.path.join(self.gt_dir, self.gt_files[idx])\n",
    "        pcd_gt = load_pcd(gt_path)\n",
    "        pcd_full, _ = generate_rotated_view(pcd_gt, rot_angle)\n",
    "\n",
    "        # Apply random augmentations\n",
    "        if mirroring < 0.5: # mirror\n",
    "            mirror_transform = np.array([\n",
    "                [-1,  0,  0,  0],\n",
    "                [ 0,  1,  0,  0],\n",
    "                [ 0,  0,  1,  0],\n",
    "                [ 0,  0,  0,  1]\n",
    "            ])\n",
    "            pcd_full.transform(mirror_transform)\n",
    "\n",
    "        if crop_prob < 0.3: # crop\n",
    "            cd = -0.2 - crop_distance\n",
    "            y_transform = np.array([\n",
    "                [ 1,  0,  0,   0],\n",
    "                [ 0,  1,  0,  cd],\n",
    "                [ 0,  0,  1,   0],\n",
    "                [ 0,  0,  0,   1]\n",
    "            ])\n",
    "            pcd_full.transform(y_transform)\n",
    "            pcd_full = pcd_full.crop(self.aabb)\n",
    "\n",
    "        # Normalize point cloud into bounding box and construct ground truth tensor\n",
    "        norm_pcd_full = normalize(pcd_full)\n",
    "        target_points = np.asarray(norm_pcd_full.points, dtype=np.uint8)\n",
    "        for (x, y, z) in target_points:\n",
    "            target_volume[x, y, z] = 1\n",
    "\n",
    "        target_tensor = torch.tensor(target_volume, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Return both prepared tensors\n",
    "        return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrct helper arrays and tensors\n",
    "ones_array = np.ones((64,128,64), dtype=np.float32)\n",
    "ones = torch.tensor(ones_array, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "block_3x3_array = np.ones((3,3,3), dtype=np.float32) * 28\n",
    "block_3x3t = torch.tensor(block_3x3_array, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "block_5x5_array = np.ones((5,5,5), dtype=np.float32) * 126\n",
    "block_5x5t = torch.tensor(block_5x5_array, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "# ==================================================================================================\n",
    "#  Voxel Dataset\n",
    "# ==================================================================================================\n",
    "def custom_loss(P, T):\n",
    "    # P = Prediction\n",
    "    # T = Target\n",
    "\n",
    "    # Use BCE loss\n",
    "    bce_loss_fn = nn.BCELoss(reduction=\"none\")\n",
    "    bce_loss = bce_loss_fn(P, T)\n",
    "\n",
    "    # Apply block filters on target tensor\n",
    "    block_3x3 = F.conv3d(T, block_3x3t, padding = 1)\n",
    "    block_5x5 = F.conv3d(T, block_5x5t, padding = 2)\n",
    "\n",
    "    # Construct custom weight, increase weight at area around the targe points\n",
    "    W = ones + (20 * T) + (20 * torch.clamp(block_3x3, 0, 1)) + (20 * torch.clamp(block_5x5, 0, 1))\n",
    "    combined_loss = bce_loss * W\n",
    "    return combined_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================\n",
    "#  Voxel Auto Encoder\n",
    "# ==================================================================================================\n",
    "class VoxelAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VoxelAutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder path\n",
    "        self.enc1 = self.double_conv(1, 16)\n",
    "        self.enc2 = self.double_conv(16, 32)\n",
    "        self.enc3 = self.double_conv(32, 64)\n",
    "        self.enc4 = self.double_conv(64, 128)\n",
    "        \n",
    "        # Downsampling layers\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.double_conv(128, 256)\n",
    "        \n",
    "        # Decoder path\n",
    "        self.upconv4 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.double_conv(256, 128)\n",
    "        self.upconv3 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.double_conv(128, 64)\n",
    "        self.upconv2 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.double_conv(64, 32)\n",
    "        self.upconv1 = nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.double_conv(32, 16)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final = nn.Conv3d(16, 1, kernel_size=1)  # Output channels = 1\n",
    "\n",
    "        # Sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def double_conv(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool(enc1))\n",
    "        enc3 = self.enc3(self.pool(enc2))\n",
    "        enc4 = self.enc4(self.pool(enc3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(enc4))\n",
    "        \n",
    "        # Decoder\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = self.dec4(torch.cat((dec4, enc4), dim=1))\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = self.dec3(torch.cat((dec3, enc3), dim=1))\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = self.dec2(torch.cat((dec2, enc2), dim=1))\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = self.dec1(torch.cat((dec1, enc1), dim=1))\n",
    "        \n",
    "        # Final output layer\n",
    "        out = self.final(dec1)\n",
    "        \n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"D:/3d_dataset/norms_4000\"\n",
    "output_path = \"D:/3d_dataset/norms_10000\"\n",
    "\n",
    "batch_size = 1\n",
    "train_split = 0.8\n",
    "torch.manual_seed(42)\n",
    "num_epochs = 2\n",
    "\n",
    "weights_pth = \"weights.pth\"\n",
    "trains_npy = \"train_losses.npy\"\n",
    "tests_npy = \"test_losses.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▉        | 783/4176 [03:29<15:07,  3.74 batch/s]\n",
      "Training the network:   0%|          | 0/2 [03:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(tests_npy, all_test_losses_epoch)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Apply model Training\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 39\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     38\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 39\u001b[0m     train_losses_epoch\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     41\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(train_losses_epoch)\n\u001b[0;32m     42\u001b[0m all_train_losses_epoch\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==================================================================================================\n",
    "#  Train Model\n",
    "# ==================================================================================================\n",
    "def train_model():\n",
    "    # Prepare Dataloder, split, optimizer and model\n",
    "    dataset = VoxelDataset(input_path, output_path)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(total_size * train_split)\n",
    "    test_size = total_size - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    model = VoxelAutoEncoder()\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model = model.to(device)\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "    # Arrays to track train and test losses\n",
    "    best_epoch_loss = float('inf')\n",
    "    all_train_losses_epoch = []\n",
    "    all_test_losses_epoch = []\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in tqdm(range(1, num_epochs + 1), desc=\"Training the network\"):\n",
    "\n",
    "        # Train epoch\n",
    "        model.train()\n",
    "        train_losses_epoch = []\n",
    "        with tqdm(train_loader, unit=\" batch\") as tepoch:\n",
    "            for idx, (inputs, targets) in enumerate(tepoch):\n",
    "                tepoch.set_description(\"Epoch {}\".format(epoch))\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = custom_loss(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses_epoch.append(loss.item())\n",
    "\n",
    "            train_loss = np.mean(train_losses_epoch)\n",
    "            all_train_losses_epoch.append(train_loss)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train-Loss: {train_loss:.6f}\")\n",
    "        \n",
    "        # Test epoch\n",
    "        model.eval()\n",
    "        test_losses_epoch = []\n",
    "        with torch.no_grad():\n",
    "            with tqdm(test_loader, unit=\" batch\") as tepoch:\n",
    "                for idx, (inputs, targets) in enumerate(tepoch):\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = custom_loss(outputs, targets)\n",
    "                    test_losses_epoch.append(loss.item())\n",
    "\n",
    "        test_loss = np.mean(test_losses_epoch)\n",
    "        all_test_losses_epoch.append(test_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Test-Loss: {test_loss:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if (test_loss < best_epoch_loss):\n",
    "            best_epoch_loss = test_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            \n",
    "            torch.save(best_model.state_dict(), weights_pth)\n",
    "            print(\"Model saved to: \", weights_pth)\n",
    "\n",
    "        # Print results and save losses as \".npy\" file\n",
    "        print(\"Training losses: \")\n",
    "        print(all_train_losses_epoch)\n",
    "        print(\"Test losses:\")\n",
    "        print(all_test_losses_epoch)\n",
    "        np.save(trains_npy, all_train_losses_epoch)\n",
    "        np.save(tests_npy, all_test_losses_epoch)\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    torch.save(best_model.state_dict(), weights_pth)\n",
    "    print(\"Model saved to: \", weights_pth)\n",
    "    print(\"Training losses: \")\n",
    "    print(all_train_losses_epoch)\n",
    "    print(\"Test losses:\")\n",
    "    print(all_test_losses_epoch)\n",
    "    np.save(trains_npy, all_train_losses_epoch)\n",
    "    np.save(tests_npy, all_test_losses_epoch)\n",
    "\n",
    "# Apply model Training\n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
